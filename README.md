# Autogenerated Anki Decks for Language Introduction

A small, scriptable pipeline that generates beginner-friendly sentence cards with audio and exports them as an Anki deck. The current repo targets **Tagalog**, but the same process can be quickly retargeted to other languages with an LLM edit pass. For updating any single script to another language, you can just ask an AI (e.g., DeepSeek), to revise each given script, see e.g. **`L2change.md`** for a prompt.

## What the pipeline does

The pipeline (1) uses **`gen_lists.txt`** with an LLM to produce frequency-based word buckets (`WORD_BUCKETS`) and a curated set of beginner grammar points (`GRAMMAR_POINTS`); (2) **`gen_sentence.py`** composes validated example sentences (ensuring coverage of target words/points), adds short English notes, and writes a timestamped JSON; (3) **`gen_voice.py`** synthesizes per-item WAV audio via system TTS; and (4) **`gen_card.py`** builds an Anki `.apkg` with both directions (L2→EN and EN→L2), bundling audio and metadata.    

## Repo layout

* `gen_lists.txt` — LLM prompts to (re)build word/grammar lists (step 1). 
* `word_list.py`, `grammar_list.py` — seed data generated by gen_lists.txt prompts.
* `gen_sentence.py` — generate `json/tl_cards_*.json` (step 2). 
* `gen_voice.py` — synthesize WAV audio per card (step 3). 
* `gen_card.py` — package the Anki deck from JSON + audio (step 4). 
* `L2change.md` — example prompt for retargeting any single script to another language.

## Requirements

* Python 3.9+
* Packages: `genanki`, `requests`, and an OpenAI-compatible client
* Windows + **Balabolka** (`bal4web.exe`) for TTS using Microsoft voices

## Setup

```bash
pip install genanki requests openai
```

Provide an API key via `OPENAI_API_KEY` (env) or a local `config.json`.
If needed, edit `BAL4WEB` and voice names in `gen_voice.py`.

## Usage

1. **Prepare lists (via `gen_lists.txt`)**
   Use `gen_lists.txt` to run the three prompts and create:

* a ~500-item frequency **word list** and `WORD_BUCKETS` (greetings/expressions/grammar_drills),
* **40–80 grammar points** (`GRAMMAR_POINTS` module).
  Save to `word_list.py` / `grammar_list.py`. (The scripts later import these modules at runtime.)  

2. **Generate cards (JSON)**

```bash
python gen_sentence.py
```

This script imports your `word_list.py` / `grammar_list.py`, calls an OpenAI-compatible chat endpoint, and writes a timestamped JSON like `json/tl_cards_YYYYMMDD_HHMM.json` plus a small usage summary. A partial checkpoint JSON file is written during generation. For convenience, you can point later steps at the current file:

```bash
cp json/tl_cards_YYYYMMDD_HHMM.json json/tl_cards.json
```

**Notes:**

* The script expects `WORD_BUCKETS` and `GRAMMAR_POINTS` to be defined; it validates outputs and enforces that targets actually appear in the Tagalog sentences.
* There’s a small built-in Tagalog detector and Wiktionary lookups to enrich card metadata (IPA, word breakdown).
* `TEST_MODE` defaults to **True** to produce a tiny sample; set it to **False** for full generation.
* API usage is recorded to `json/openai_usage_summary_*.json`. 

3. **Synthesize audio**

```bash
python gen_voice.py
```

Audio is currently generated via **Balabolka**’s `bal4web.exe` using Microsoft voices (Tagalog `fil-PH`), probing for **Blessica** and **Angelo** and saving one WAV per card per voice as `readings/{id}_Blessica.wav` and/or `readings/{id}_Angelo.wav`. This can be rather straightforwardly to modify to other TTS services and voices.

4. **Build the Anki deck**

```bash
python gen_card.py
```

This reads `json/tl_cards.json`, looks for matching audio in `readings/`, and creates an `.apkg` named like `AITagalogIntro_YYYYMMDD_HHMM.apkg`. Cards are added in **both directions** per 30-item block, tagged `v1` (TL→EN) and `v2` (EN→TL), and include dual-audio fields if present. Import into Anki via **File → Import…**. 

### More details & caveats

* **LLM stage (`gen_sentence.py`)**

  * Loads config from `config.json` or `OPENAI_API_KEY`.
  * Imports `word_list.py`/`grammar_list.py` (must exist and define the expected symbols).
  * For each target, it prompts the LLM to produce a concise Tagalog sentence + English gloss, verifies the target’s presence, and writes structured JSON entries with optional IPA/word-breakdown from Wiktionary.
  * If you see only a tiny sample, disable `TEST_MODE`. 

* **Voice stage (`gen_voice.py`)**

  * Windows-only as written (depends on Balabolka + Microsoft voices).
  * Probes voice names and synthesizes to `readings/`. You might need to adjust `BAL4WEB`, voice labels, or `LANG_CODE`. If your system doesn’t have Tagalog voices, either skip audio (the deck still builds) or switch to another TTS provider. 

* **Deck stage (`gen_card.py`)**

  * Expects the *non-timestamped* `json/tl_cards.json`; if you generated a timestamped file, copy it to that path first.
  * Looks specifically for `{id}_Angelo.wav` / `{id}_Blessica.wav` (filenames matter). Missing audio is tolerated—the note is created without that channel.
  * Builds both directions and includes metadata (IPA, breakdown, stage, grammar id/title) on the back. 

* **Other languages / services**

  * For LLM retargeting, re-run step 1’s prompts for your target language, then repeat steps 2–4.
  * For TTS on **macOS/Linux** or where Microsoft Tagalog voices aren’t available, swap out `gen_voice.py` for another service (e.g., Azure TTS, ElevenLabs, Coqui-TTS, gTTS) and keep the output naming convention (`readings/{id}_VoiceName.wav`). The deck builder will pick up any files that match those names. 


## Notes

* This repo is **not** actively maintained.
* Upload the script and ask any AI to explain more details.

## License

GPL.
